<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Toolshed AI - Vercel Edition</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .overlay { position: absolute; top: 0; left: 0; pointer-events: none; }
        canvas { max-width: 100%; height: auto; }
    </style>
</head>
<body class="bg-gray-900 text-white min-h-screen p-4">
    <div class="max-w-4xl mx-auto">
        <header class="text-center mb-8">
            <h1 class="text-4xl font-bold text-green-400">üõ†Ô∏è Toolshed AI</h1>
            <p class="text-gray-400">Detect workbenches and simulate your layout</p>
        </header>

        <div class="grid grid-cols-1 md:grid-cols-3 gap-8">
            <!-- Controls -->
            <div class="bg-gray-800 p-6 rounded-xl shadow-lg">
                <h2 class="text-xl font-semibold mb-4">Controls</h2>
                <div class="space-y-4">
                    <button id="snap" class="w-full bg-green-500 hover:bg-green-600 text-white font-bold py-2 px-4 rounded transition">
                        Capture & AI Detect
                    </button>
                    <p class="text-xs text-gray-400 text-center italic">OR click on the image below to manually select a workbench area</p>
                    <button id="clear" class="w-full bg-red-500 hover:bg-red-600 text-white font-bold py-2 px-4 rounded transition">
                        Reset View
                    </button>
                    <div class="mt-6">
                        <label class="block text-sm font-medium mb-1">Add Simulation Item</label>
                        <select id="itemType" class="w-full bg-gray-700 rounded p-2">
                            <option>Shelf</option>
                            <option>Tool Rack</option>
                            <option>Storage Bin</option>
                            <option>Cabinet</option>
                        </select>
                    </div>
                </div>
                
                <div id="status" class="mt-4 text-sm text-yellow-400"></div>
            </div>

            <!-- Viewport -->
            <div class="md:col-span-2 relative bg-black rounded-xl overflow-hidden shadow-2xl border-2 border-gray-700 cursor-crosshair">
                <video id="video" class="w-full h-full object-cover" autoplay playsinline></video>
                <canvas id="canvas" class="hidden"></canvas>
                <img id="result" class="hidden w-full h-full object-cover">
                <div id="manual-overlay" class="absolute inset-0"></div>
            </div>
        </div>

        <div id="results-list" class="mt-8 grid grid-cols-1 md:grid-cols-4 gap-4">
            <!-- Detection results will appear here -->
        </div>
    </div>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const snap = document.getElementById('snap');
        const resultImg = document.getElementById('result');
        const status = document.getElementById('status');
        const resultsList = document.getElementById('results-list');
        const manualOverlay = document.getElementById('manual-overlay');
        let detections = [];

        // Access Camera
        async function initCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
                video.srcObject = stream;
            } catch (err) {
                status.innerText = "Error: Camera access denied";
            }
        }

        // Manual Selection Logic
        manualOverlay.addEventListener('mousedown', (e) => {
            if (video.classList.contains('hidden') && !resultImg.classList.contains('hidden')) {
                const rect = manualOverlay.getBoundingClientRect();
                const x = (e.clientX - rect.left) / rect.width * resultImg.naturalWidth;
                const y = (e.clientY - rect.top) / rect.height * resultImg.naturalHeight;
                
                // Add a manual workbench box
                const manualBox = {
                    x: x - 100,
                    y: y - 50,
                    w: 200,
                    h: 100,
                    type: 'Manual Workbench'
                };
                detections.push(manualBox);
                updateDetectionsUI();
                drawManualBox(e.clientX - rect.left, e.clientY - rect.top);
            }
        });

        function drawManualBox(x, y) {
            const box = document.createElement('div');
            box.style.left = `${x - 50}px`;
            box.style.top = `${y - 25}px`;
            box.style.width = '100px';
            box.style.height = '50px';
            box.className = "absolute border-2 border-blue-500 bg-blue-500 bg-opacity-20 pointer-events-none";
            manualOverlay.appendChild(box);
        }

        function updateDetectionsUI() {
            resultsList.innerHTML = '';
            detections.forEach((d, i) => {
                const div = document.createElement('div');
                div.className = "bg-gray-800 p-3 rounded border border-green-500 relative";
                div.innerHTML = `
                    <span class='font-bold text-green-400'>#${i+1} ${d.type}</span><br>
                    Size: ${Math.round(d.w)}x${Math.round(d.h)}
                `;
                resultsList.appendChild(div);
            });
        }

        snap.addEventListener('click', async () => {
            status.innerText = "AI is scanning for surfaces...";
            const context = canvas.getContext('2d');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
            
            const imageData = canvas.toDataURL('image/jpeg');
            
            try {
                const response = await fetch('/process', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ image: imageData })
                });
                
                const data = await response.json();
                if (data.image) {
                    resultImg.src = data.image;
                    resultImg.classList.remove('hidden');
                    video.classList.add('hidden');
                    detections = data.detections;
                    
                    if (detections.length === 0) {
                        status.innerText = "AI missed it! Click on the image to manually place a workbench.";
                    } else {
                        status.innerText = `AI detected ${detections.length} surfaces! You can also click to add more.`;
                    }
                    
                    updateDetectionsUI();
                }
            } catch (err) {
                status.innerText = "Error processing image";
            }
        });

        document.getElementById('clear').addEventListener('click', () => {
            resultImg.classList.add('hidden');
            video.classList.remove('hidden');
            resultsList.innerHTML = '';
            manualOverlay.innerHTML = '';
            detections = [];
            status.innerText = "";
        });

        initCamera();
    </script>
</body>
</html>
